{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31572a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from math import floor, log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc8968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_and_format_decimal(x, n=1):\n",
    "    if x > 0:\n",
    "        x = round(x, n - int(floor(log10(abs(x)))))\n",
    "        return \"{:#.2g}\".format(x)\n",
    "    else:\n",
    "        return '0.0'\n",
    "\n",
    "def round_and_format_scientific(x, n=1):\n",
    "    if x > 0:\n",
    "        x = round(x, n - int(floor(log10(abs(x)))))\n",
    "        return f\"{x:.0E}\"\n",
    "    else:\n",
    "        return '0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af205d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation_summaries(base_path=\"sciplex3/\"):\n",
    "    \"\"\"\n",
    "    Collects evaluation summary statistics grouped by model_name.\n",
    "\n",
    "    Returns:\n",
    "        dict: {model_name: [DataFrame, ...]} where each DataFrame is a summary.csv for a run.\n",
    "    \"\"\"\n",
    "    summaries = defaultdict(list)\n",
    "    if not os.path.isdir(base_path):\n",
    "        raise ValueError(f\"Base path does not exist: {base_path}\")\n",
    "\n",
    "    for model_name in os.listdir(base_path):\n",
    "        model_dir = os.path.join(base_path, model_name)\n",
    "        if not os.path.isdir(model_dir):\n",
    "            continue\n",
    "        for run_id in os.listdir(model_dir):\n",
    "            run_dir = os.path.join(model_dir, run_id)\n",
    "            eval_path = os.path.join(run_dir, \"evaluation\", \"summary.csv\")\n",
    "            if os.path.isfile(eval_path):\n",
    "                try:\n",
    "                    df = pd.read_csv(eval_path, index_col=0)\n",
    "                    summaries[model_name].append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to read {eval_path}: {e}\")\n",
    "        \n",
    "        # combine all dataframes for this model\n",
    "        if summaries[model_name]:\n",
    "            combined_df = pd.concat(summaries[model_name], axis=1)\n",
    "            summaries[model_name] = combined_df\n",
    "    \n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1803915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['decoder-cov', 'latent', 'latent-scgpt', 'decoder', 'sams-vae', 'linear'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_dict = get_evaluation_summaries()\n",
    "summary_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85f8e3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decoder-cov</th>\n",
       "      <th>latent</th>\n",
       "      <th>latent-scgpt</th>\n",
       "      <th>decoder</th>\n",
       "      <th>sams-vae</th>\n",
       "      <th>linear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_average</th>\n",
       "      <td>0.023 ± 1E-04</td>\n",
       "      <td>0.028 ± 1E-02</td>\n",
       "      <td>0.019 ± 3E-04</td>\n",
       "      <td>0.019 ± 3E-04</td>\n",
       "      <td>0.020 ± 2E-05</td>\n",
       "      <td>0.030 ± 4E-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_rank_average</th>\n",
       "      <td>0.47 ± 0.0</td>\n",
       "      <td>0.26 ± 6E-02</td>\n",
       "      <td>0.15 ± 2E-02</td>\n",
       "      <td>0.15 ± 2E-02</td>\n",
       "      <td>0.19 ± 2E-02</td>\n",
       "      <td>0.27 ± 2E-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine_pca_average</th>\n",
       "      <td>0.93 ± 2E-04</td>\n",
       "      <td>0.92 ± 7E-02</td>\n",
       "      <td>0.97 ± 1E-03</td>\n",
       "      <td>0.97 ± 1E-03</td>\n",
       "      <td>0.93 ± 7E-04</td>\n",
       "      <td>0.92 ± 1E-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine_rank_pca_average</th>\n",
       "      <td>0.43 ± 0.0</td>\n",
       "      <td>0.26 ± 6E-02</td>\n",
       "      <td>0.15 ± 1E-02</td>\n",
       "      <td>0.15 ± 1E-02</td>\n",
       "      <td>0.069 ± 6E-03</td>\n",
       "      <td>0.28 ± 7E-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine_logfc</th>\n",
       "      <td>0.30 ± 2E-02</td>\n",
       "      <td>0.32 ± 1E-01</td>\n",
       "      <td>0.33 ± 7E-03</td>\n",
       "      <td>0.33 ± 7E-03</td>\n",
       "      <td>0.46 ± 5E-03</td>\n",
       "      <td>0.15 ± 6E-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine_rank_logfc</th>\n",
       "      <td>0.47 ± 0.0</td>\n",
       "      <td>0.28 ± 1E-01</td>\n",
       "      <td>0.20 ± 1E-02</td>\n",
       "      <td>0.20 ± 1E-02</td>\n",
       "      <td>0.21 ± 3E-02</td>\n",
       "      <td>0.28 ± 2E-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_score_scores</th>\n",
       "      <td>0.0 ± 7E-03</td>\n",
       "      <td>0.0 ± 1E-02</td>\n",
       "      <td>0.0 ± 2E-03</td>\n",
       "      <td>0.0 ± 2E-03</td>\n",
       "      <td>0.0 ± 8E-03</td>\n",
       "      <td>0.0 ± 2E-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_k_recall_scores</th>\n",
       "      <td>0.00093 ± 5E-04</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>0.0079 ± 5E-04</td>\n",
       "      <td>0.0079 ± 5E-04</td>\n",
       "      <td>0.00016 ± 1E-04</td>\n",
       "      <td>0.0036 ± 3E-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmd_pca</th>\n",
       "      <td>2.1 ± 2E-03</td>\n",
       "      <td>2.0 ± 2E-01</td>\n",
       "      <td>1.9 ± 5E-03</td>\n",
       "      <td>1.9 ± 5E-03</td>\n",
       "      <td>0.69 ± 1E-02</td>\n",
       "      <td>0.76 ± 9E-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmd_rank_pca</th>\n",
       "      <td>0.43 ± 0.0</td>\n",
       "      <td>0.26 ± 5E-02</td>\n",
       "      <td>0.15 ± 1E-02</td>\n",
       "      <td>0.15 ± 1E-02</td>\n",
       "      <td>0.060 ± 3E-03</td>\n",
       "      <td>0.30 ± 3E-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmd_none</th>\n",
       "      <td>4.3 ± 1E-03</td>\n",
       "      <td>4.3 ± 2E-01</td>\n",
       "      <td>4.2 ± 4E-03</td>\n",
       "      <td>4.2 ± 4E-03</td>\n",
       "      <td>2.5 ± 2E-02</td>\n",
       "      <td>2.2 ± 7E-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmd_rank_none</th>\n",
       "      <td>0.49 ± 0.0</td>\n",
       "      <td>0.26 ± 6E-02</td>\n",
       "      <td>0.16 ± 2E-02</td>\n",
       "      <td>0.16 ± 2E-02</td>\n",
       "      <td>0.30 ± 8E-03</td>\n",
       "      <td>0.31 ± 1E-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             decoder-cov         latent    latent-scgpt  \\\n",
       "metric                                                                    \n",
       "rmse_average               0.023 ± 1E-04  0.028 ± 1E-02   0.019 ± 3E-04   \n",
       "rmse_rank_average             0.47 ± 0.0   0.26 ± 6E-02    0.15 ± 2E-02   \n",
       "cosine_pca_average          0.93 ± 2E-04   0.92 ± 7E-02    0.97 ± 1E-03   \n",
       "cosine_rank_pca_average       0.43 ± 0.0   0.26 ± 6E-02    0.15 ± 1E-02   \n",
       "cosine_logfc                0.30 ± 2E-02   0.32 ± 1E-01    0.33 ± 7E-03   \n",
       "cosine_rank_logfc             0.47 ± 0.0   0.28 ± 1E-01    0.20 ± 1E-02   \n",
       "r2_score_scores              0.0 ± 7E-03    0.0 ± 1E-02     0.0 ± 2E-03   \n",
       "top_k_recall_scores      0.00093 ± 5E-04      0.0 ± 0.0  0.0079 ± 5E-04   \n",
       "mmd_pca                      2.1 ± 2E-03    2.0 ± 2E-01     1.9 ± 5E-03   \n",
       "mmd_rank_pca                  0.43 ± 0.0   0.26 ± 5E-02    0.15 ± 1E-02   \n",
       "mmd_none                     4.3 ± 1E-03    4.3 ± 2E-01     4.2 ± 4E-03   \n",
       "mmd_rank_none                 0.49 ± 0.0   0.26 ± 6E-02    0.16 ± 2E-02   \n",
       "\n",
       "                                decoder         sams-vae          linear  \n",
       "metric                                                                    \n",
       "rmse_average              0.019 ± 3E-04    0.020 ± 2E-05   0.030 ± 4E-04  \n",
       "rmse_rank_average          0.15 ± 2E-02     0.19 ± 2E-02    0.27 ± 2E-03  \n",
       "cosine_pca_average         0.97 ± 1E-03     0.93 ± 7E-04    0.92 ± 1E-04  \n",
       "cosine_rank_pca_average    0.15 ± 1E-02    0.069 ± 6E-03    0.28 ± 7E-04  \n",
       "cosine_logfc               0.33 ± 7E-03     0.46 ± 5E-03    0.15 ± 6E-03  \n",
       "cosine_rank_logfc          0.20 ± 1E-02     0.21 ± 3E-02    0.28 ± 2E-03  \n",
       "r2_score_scores             0.0 ± 2E-03      0.0 ± 8E-03     0.0 ± 2E-03  \n",
       "top_k_recall_scores      0.0079 ± 5E-04  0.00016 ± 1E-04  0.0036 ± 3E-04  \n",
       "mmd_pca                     1.9 ± 5E-03     0.69 ± 1E-02    0.76 ± 9E-04  \n",
       "mmd_rank_pca               0.15 ± 1E-02    0.060 ± 3E-03    0.30 ± 3E-04  \n",
       "mmd_none                    4.2 ± 4E-03      2.5 ± 2E-02     2.2 ± 7E-03  \n",
       "mmd_rank_none              0.16 ± 2E-02     0.30 ± 8E-03    0.31 ± 1E-03  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict = {}\n",
    "for k, runs_df in summary_dict.items():\n",
    "    avg = runs_df.mean(axis=1).apply(lambda x: round_and_format_decimal(x))\n",
    "    std = runs_df.std(axis=1).apply(lambda x: round_and_format_scientific(x))\n",
    "\n",
    "    metrics = pd.Series('', index=runs_df.index)\n",
    "    for m in runs_df.index.values:\n",
    "        metrics.loc[m] = avg.loc[m] + \" ± \" + std.loc[m]\n",
    "\n",
    "    metrics_dict[k] = metrics\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_dict)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92550888",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(\"sciplex3_metrics_fixed.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
