{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to training_metrics.csv\n",
      "\n",
      "train_loss:\n",
      "  Saturation step: 199\n",
      "  Saturation at: 7.4% of training\n",
      "  Initial loss: 0.1743\n",
      "  Final loss: 0.0529\n",
      "\n",
      "val_loss_step:\n",
      "  Saturation step: 10\n",
      "  Saturation at: 1.8% of training\n",
      "  Initial loss: 0.0579\n",
      "  Final loss: 0.0495\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.core.util import event_pb2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def read_tensorboard_logs(log_dir):\n",
    "    \"\"\"\n",
    "    Read TensorBoard event files and extract metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - log_dir: Path to directory containing TensorBoard event files\n",
    "    \n",
    "    Returns:\n",
    "    - metrics_df: DataFrame with columns [step, epoch, metric_name, value]\n",
    "    \"\"\"\n",
    "    log_path = Path(log_dir)\n",
    "    event_files = list(log_path.glob(\"events.out.tfevents.*\"))\n",
    "    \n",
    "    if not event_files:\n",
    "        raise ValueError(f\"No TensorBoard event files found in {log_dir}\")\n",
    "    \n",
    "    all_metrics = []\n",
    "    \n",
    "    for event_file in event_files:\n",
    "        for record in tf.data.TFRecordDataset(str(event_file)):\n",
    "            event = event_pb2.Event.FromString(record.numpy())\n",
    "            \n",
    "            # Extract scalar values\n",
    "            for value in event.summary.value:\n",
    "                all_metrics.append({\n",
    "                    'step': event.step,\n",
    "                    'wall_time': event.wall_time,\n",
    "                    'metric_name': value.tag,\n",
    "                    'value': value.simple_value\n",
    "                })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(all_metrics)\n",
    "    return metrics_df\n",
    "\n",
    "def calculate_saturation_point(metrics_df, metric_name='train/loss', threshold_pct=0.1):\n",
    "    \"\"\"\n",
    "    Calculate the first step where the model reaches within threshold_pct of final loss.\n",
    "    \n",
    "    Parameters:\n",
    "    - metrics_df: DataFrame from read_tensorboard_logs\n",
    "    - metric_name: Name of the metric to analyze (e.g., 'train/loss')\n",
    "    - threshold_pct: Percentage threshold (default 0.1 for 10%)\n",
    "    \n",
    "    Returns:\n",
    "    - saturation_dict: Dictionary with saturation metrics\n",
    "    \"\"\"\n",
    "    # Filter for the specific metric\n",
    "    metric_data = metrics_df[metrics_df['metric_name'] == metric_name].copy()\n",
    "    metric_data = metric_data.sort_values('step')\n",
    "    \n",
    "    if len(metric_data) == 0:\n",
    "        raise ValueError(f\"Metric '{metric_name}' not found in data\")\n",
    "    \n",
    "    # Get final loss value (average of last 10% of training)\n",
    "    n_final = max(1, len(metric_data) // 10)\n",
    "    final_loss = metric_data['value'].tail(n_final).mean()\n",
    "    \n",
    "    # Get initial loss\n",
    "    initial_loss = metric_data['value'].iloc[0]\n",
    "    \n",
    "    # Calculate threshold value\n",
    "    threshold_value = final_loss * (1 + threshold_pct)\n",
    "    \n",
    "    # Find first step where loss is within threshold of final value\n",
    "    within_threshold = metric_data[metric_data['value'] <= threshold_value]\n",
    "    \n",
    "    if len(within_threshold) == 0:\n",
    "        saturation_step = None\n",
    "        saturation_epoch = None\n",
    "    else:\n",
    "        saturation_step = within_threshold['step'].iloc[0]\n",
    "        saturation_epoch = saturation_step  # Adjust if you track epochs separately\n",
    "    \n",
    "    return {\n",
    "        'saturation_step': saturation_step,\n",
    "        'initial_loss': initial_loss,\n",
    "        'final_loss': final_loss,\n",
    "        'threshold_value': threshold_value,\n",
    "        'total_steps': metric_data['step'].max(),\n",
    "        'saturation_pct': (saturation_step / metric_data['step'].max() * 100) if saturation_step else None\n",
    "    }\n",
    "\n",
    "def extract_all_metrics(log_dir, output_csv=None):\n",
    "    \"\"\"\n",
    "    Extract all metrics and calculate saturation for train/val loss.\n",
    "    \n",
    "    Parameters:\n",
    "    - log_dir: Path to TensorBoard log directory\n",
    "    - output_csv: Optional path to save metrics CSV\n",
    "    \n",
    "    Returns:\n",
    "    - metrics_df: DataFrame with all metrics\n",
    "    - saturation_metrics: Dictionary with saturation analysis\n",
    "    \"\"\"\n",
    "    # Read metrics\n",
    "    metrics_df = read_tensorboard_logs(log_dir)\n",
    "    \n",
    "    # Save to CSV if requested\n",
    "    if output_csv:\n",
    "        metrics_df.to_csv(output_csv, index=False)\n",
    "        print(f\"Metrics saved to {output_csv}\")\n",
    "    \n",
    "    # Calculate saturation for different metrics\n",
    "    saturation_metrics = {}\n",
    "    \n",
    "    for metric_name in ['train_loss', 'val_loss_step']:\n",
    "        try:\n",
    "            saturation = calculate_saturation_point(metrics_df, metric_name)\n",
    "            saturation_metrics[metric_name] = saturation\n",
    "            print(f\"\\n{metric_name}:\")\n",
    "            print(f\"  Saturation step: {saturation['saturation_step']}\")\n",
    "            print(f\"  Saturation at: {saturation['saturation_pct']:.1f}% of training\")\n",
    "            print(f\"  Initial loss: {saturation['initial_loss']:.4f}\")\n",
    "            print(f\"  Final loss: {saturation['final_loss']:.4f}\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    return metrics_df, saturation_metrics\n",
    "\n",
    "# Usage example\n",
    "log_dir = \"/gpfs/home/asun/jin_lab/perturbench/1_train/logs/train/multiruns/2025-09-22_15-59-22/0_boli_qual_high_amt_high/tensorboard/version_0\"\n",
    "metrics_df, saturation_metrics = extract_all_metrics(\n",
    "    log_dir, \n",
    "    output_csv=\"training_metrics.csv\"\n",
    ")\n",
    "\n",
    "# Access specific saturation point\n",
    "#train_saturation_step = saturation_metrics['train/loss']['saturation_step']\n",
    "#print(f\"\\nTraining speed saturation: {train_saturation_step} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metric_name\n",
       "val_loss_step                   560\n",
       "epoch                           278\n",
       "train_loss                      268\n",
       "lr-Adam                          10\n",
       "lr-Adam-momentum                 10\n",
       "val_loss_epoch                   10\n",
       "hp_metric                         2\n",
       "_hparams_/experiment              2\n",
       "_hparams_/session_start_info      2\n",
       "_hparams_/session_end_info        2\n",
       "rmse_average                      1\n",
       "rmse_rank_average                 1\n",
       "cosine_logfc                      1\n",
       "cosine_rank_logfc                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df[\"metric_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perturbbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
